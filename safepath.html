<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="SAFEPATH: Preventing Harmful Reasoning in Chain-of-Thought via Early Alignment">
  <meta name="keywords" content="DUSK, Benchmark, Knowledge Unlearning, Multisource Unlearning, Large Language Models">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SAFEPATH: Preventing Harmful Reasoning in Chain-of-Thought via Early Alignment</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/Icon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <style>
    body {
      background-color: #ffffff;
      color: #1e2a3a;
      font-family: 'Noto Sans', sans-serif;
    }
  
    .hero {
        background-color: #1e3a8a;  /* ÏßÑÌïú ÌååÎûë */
        padding-top: 4rem;
        padding-bottom: 4rem;
        }
  
    .section.is-light {
      background-color: #f5f9ff;
      color: #1e2a3a;
      padding: 2rem;
      border-radius: 8px;
    }
  
    .section.is-dark-gradient {
      background: linear-gradient(to top, #0f172a, #1e3a8a);
      color: #ffffff;
      padding: 3rem 2rem;
      margin-top: 4rem;
    }
  
    .title,
    .subtitle,
    .content p {
      color: #1e2a3a !important;
    }
  
    .section.is-dark-gradient .title,
    .section.is-dark-gradient .subtitle,
    .section.is-dark-gradient .content p {
      color: #ffffff !important;
    }
  
    .publication-title {
        color: #ffffff !important;
        font-weight: 800;
        font-size: 2.8rem;
        text-shadow: 0px 2px 4px rgba(0, 0, 0, 0.25); /* ÍπäÏù¥Í∞êÎßå ÏÇ¥Ïßù */
    }
  
    .button.is-dark {
      background-color: #2563eb;
      color: #ffffff;
      border-color: #2563eb;
    }
  
    .button.is-dark:hover {
      background-color: #1d4ed8;
      border-color: #1d4ed8;
    }
  
    .publication-links .button {
      margin: 0.3rem;
    }
  
    .content a {
      color: #1d4ed8;
      text-decoration: underline;
    }
  
    .content a:hover {
      color: #1e3a8a;
    }
  
    .overview-results-image img,
    .full-results-image img {
      border-radius: 8px;
      box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
    }
  </style>
  
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title" style="color: #ffffff !important;">SAFEPATH: Preventing Harmful Reasoning in Chain-of-Thought via Early Alignment</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://cryinginitial.github.io/">Wonje Jeung</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href=".">Sangyeon Yoon</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://minsuk.com/">Minsuk Kahng</a><sup>1‚Ä†</sup>,
            </span>
            <span class="author-block">
              <a href=".">Albert No</a><sup>1‚Ä†</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Yonsei University<sup>1</sup>,</span>
            <span class="author-block">Hongik University<sup>2</sup>,</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2505.14667"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2505.14667"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/cryingInitial/SAFEPATH"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/collections/AI-ISL/model-with-safepath-6833f7e2924393051aeb4251"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      ü§ó
                  </span>
                  <span>Model & Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section>
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Large Reasoning Models (LRMs) have become powerful tools for complex problem solving, but their structured reasoning pathways can lead to unsafe outputs when exposed to harmful prompts. Existing safety alignment methods reduce harmful outputs but can degrade reasoning depth, leading to significant trade-offs in complex, multi-step tasks, and remain vulnerable to sophisticated jailbreak attacks. To address this, we introduce SAFEPATH, a lightweight alignment method that fine-tunes LRMs to emit a short, 8-token Safety Primer at the start of their reasoning, in response to harmful prompts, while leaving the rest of the reasoning process unsupervised. Empirical results across multiple benchmarks indicate that SAFEPATH effectively reduces harmful outputs while maintaining reasoning performance. Specifically, SAFEPATH reduces harmful responses by up to 90.0% and blocks 83.3% of jailbreak attempts in the DeepSeek-R1-Distill-Llama-8B model, while requiring 295.9x less compute than Direct Refusal and 314.1x less than SafeChain. We further introduce a zero-shot variant that requires no fine-tuning. In addition, we provide a comprehensive analysis of how existing methods in LLMs generalize, or fail, when applied to reasoning-centric models, revealing critical gaps and new directions for safer AI.
          </p>
        </div>
      </div>
    </div>
    </div>
    <!--/ Abstract. -->
</section>

<section>

    <!-- METHOD -->
    <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Add SAFEPATH to LRMs</h2>
        
        <!-- Paper image -->
        <div class="publication-image">
            <img src="./static/images/safepath/overview.png" alt="Description of the image"
              style="width: 100%; max-width: 900px; height: auto; display: block; margin: 0 auto;">
        </div> 

        <!-- Additional explanation below the image -->
        <div class="content" style="margin-top: 2rem;">
          <p>
            SAFEPATH is a lightweight method for aligning the behavior of Large Reasoning Models (LRMs) in the presence of harmful prompts. Instead of imposing rigid constraints or rewriting the full reasoning process, SAFEPATH introduces a short, fixed phrase called the Safety Primer at the very beginning of the model's reasoning block. This 8-token prompt (<em>"Let's think about safety first"</em>) gently guides the model toward safety-aware reasoning while preserving its overall problem-solving flow. The method applies minimal supervision only at the entry point of reasoning and relies on the model's natural ability to generate structured thoughts.
          </p>
        </div>
      </div>
    </div>
  </div>

  <!-- Results -->
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Results</h2>
        
        <!-- Summarized Results -->
        <div class="overview-results-image">
            <img src="./static/images/safepath/overview_results.png" alt="Description of the image"
              style="width: 100%; max-width: 900px; height: auto; display: block; margin: 0 auto;">
        </div> 

        <!-- Additional explanation below the image -->
        <div class="content" style="margin-top: 2rem;">
          <p>
            The figure below presents a comparison between SAFEPATH and existing alignment methods across four key dimensions: harmfulness, robustness under attack, reasoning ability, and computational cost.
            SAFEPATH achieves lower harmful response rates and greater resilience to adversarial prompts, while preserving high reasoning accuracy. Unlike prior approaches that often require extensive fine-tuning or compromise model performance, SAFEPATH provides a much more efficient solution with minimal training overhead.
            Full quantitative results are provided in the table below.
          </p>
        </div>

        <!-- Full Results -->
        <div class="full-results-image">
            <img src="./static/images/safepath/main_results.png" alt="Description of the image"
              style="width: 100%; max-width: 900px; height: auto; display: block; margin: 0 auto;">
        </div> 
    </div>
    </div>
  </div>

    <!-- Analysis -->
    <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column is-full-width">
            <h2 class="title is-3">Analysis</h2>
            
            <!-- Safety Primer -->
            <div style="display: flex; align-items: flex-start; justify-content: space-between; gap: 2rem; flex-wrap: wrap;">

                <!-- Text content -->
                <div class="content" style="flex: 1 1 500px; min-width: 300px;">
                <p>
                    SAFEPATH is trained to insert a Safety Primer only once at the beginning of a harmful prompt. In practice, however, the model learns to activate the primer multiple times when faced with unsafe reasoning paths.
            
                    The figure shows that primer activations are rare on standard benchmarks like MATH500, but increase significantly under harmful or adversarial inputs such as StrongReject and PAIR. This pattern suggests that the model adapts its behavior based on context, reintroducing the safety signal when needed.
            
                    This emergent behavior highlights SAFEPATH's ability to maintain safety awareness throughout the reasoning process without relying on heavy supervision.
                </p>
                </div>
            
                <!-- Image on the right -->
                <div style="flex: 0 0 300px;">
                <img src="./static/images/safepath/num_activations.png" alt="Safety Primer Activations"
                    style="width: 100%; height: auto; display: block;">
                </div>
            
            </div>
    
            <!-- Full Results -->
            <div class="full-results-image">
                <img src="./static/images/safepath/inference_time.png" alt="Description of the image"
                  style="width: 100%; max-width: 900px; height: auto; display: block; margin: 0 auto;">
            </div> 
    
            <div class="content" style="margin-top: 2rem;">
                <p>
                  To ensure diversity and balance, the dataset construction process controlled the distribution of key attributes such as gender, religion, nationality, and institutional affiliation.
                  This was achieved by iteratively prompting GPT-4 to generate profiles that collectively reflect a wide range of demographic and professional backgrounds.
                </p>
            </div>
        </div>
        </div>
      </div>
</section>  



<section class="section is-dark-gradient" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{jeung2025safepath,
    title={SAFEPATH: Preventing Harmful Reasoning in Chain-of-Thought via Early Alignment},
    author={Jeung, Wonje and Yoon, Sangyeon and Kahng, Minsuk and No, Albert},
    journal={arXiv preprint arXiv:2505.14667},
    year={2025}
  }</code></pre>
    </div>
  </section>
  

</body>
</html>
