<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="SAFEPATH: Preventing Harmful Reasoning in Chain-of-Thought via Early Alignment">
  <meta name="keywords" content="DUSK, Benchmark, Knowledge Unlearning, Multisource Unlearning, Large Language Models">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>SAFEPATH: Preventing Harmful Reasoning in Chain-of-Thought via Early Alignment</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/Icon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
    <style>
    body {
      background: linear-gradient(135deg, #2a1f4f 0%, #521d62 30%, #9e2179 70%, #ff6e4a 100%);
      color: #ffffff;
    }
    .section.is-light {
      background-color: rgba(255, 255, 255, 0.8);
      color: #333333;
      padding: 20px;
    }
    .content p, .title, .subtitle {
      color: #000000 !important;
    }
    .publication-title {
      color: #ff6e4a;
    }
    .button.is-dark {
      background-color: #ff6e4a;
      color: #ffffff;
      border-color: #ff6e4a;
    }
    .button.is-dark:hover {
      background-color: #e85d3d;
      border-color: #e85d3d;
    }
  </style>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <img src="./static/images/Icon.png" alt="Logo" style="max-width: 280px; margin-bottom: 40px;">
          <h1 class="title is-1 publication-title" style="color: #ffffff !important;">SAFEPATH: Preventing Harmful Reasoning in Chain-of-Thought via Early Alignment</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://cryinginitial.github.io/">Wonje Jeung</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href=".">Sangyeon Yoon</a><sup>2*</sup>,</span>
            <span class="author-block">
              <a href="https://minsuk.com/">Minsuk Kahng</a><sup>1â€ </sup>,
            </span>
            <span class="author-block">
              <a href=".">Albert No</a><sup>1â€ </sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Yonsei University<sup>1</sup>,</span>
            <span class="author-block">Hongik University<sup>2</sup>,</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2505.14667"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2505.14667"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/cryingInitial/SAFEPATH"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/collections/AI-ISL/model-with-safepath-6833f7e2924393051aeb4251"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      ðŸ¤—
                  </span>
                  <span>Model & Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Large Reasoning Models (LRMs) have become powerful tools for complex problem solving, but their structured reasoning pathways can lead to unsafe outputs when exposed to harmful prompts. Existing safety alignment methods reduce harmful outputs but can degrade reasoning depth, leading to significant trade-offs in complex, multi-step tasks, and remain vulnerable to sophisticated jailbreak attacks. To address this, we introduce <p style="font-variant-caps: all-small-caps;">SafePath</p>, a lightweight alignment method that fine-tunes LRMs to emit a short, 8-token Safety Primer at the start of their reasoning, in response to harmful prompts, while leaving the rest of the reasoning process unsupervised. Empirical results across multiple  benchmarks indicate that \textsc{SafePath} effectively reduces harmful outputs while maintaining reasoning performance. Specifically, \textsc{SafePath} reduces harmful responses by up to 90.0\% and blocks 83.3\% of jailbreak attempts in the DeepSeek-R1-Distill-Llama-8B model, while requiring 295.9x less compute than Direct Refusal and 314.1x less than SafeChain. We further introduce a zero-shot variant that requires no fine-tuning. In addition, we provide a comprehensive analysis of how existing methods in LLMs generalize, or fail, when applied to reasoning-centric models, revealing critical gaps and new directions for safer AI.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  <!-- Paper image. -->
  <div class="columns is-centered has-text-centered">
    <div class="column is-full-width">
      <div class="publication-image">
        <img id="teaser" src="./static/images/safepath/images.png" alt="Teaser Image"
           style="width: 100%; max-width: 900px; height: auto; display: block; margin: 0 auto;">
      </div>
    </div>
  </div>
  <!--/ Paper image. -->
</section>

<section class="section is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Data Construction</h2>

        <!-- Additional explanation below the image -->
        <div class="content" style="margin-top: 2rem;">
          <p>
            To ensure diversity and balance, the dataset construction process controlled the distribution of key attributes such as gender, religion, nationality, and institutional affiliation.
            This was achieved by iteratively prompting GPT-4 to generate profiles that collectively reflect a wide range of demographic and professional backgrounds.
          </p>
        </div>

        <!-- Paper image -->
        <div class="publication-image">
          <img src="./static/images/DataConstruction.png" alt="Description of the image"
            style="width: 100%; max-width: 900px; height: auto; display: block; margin: 0 auto;">
        </div> 
      </div>
    </div>
  </div>
</section>  
  
<section class="section is-light">
  <div class="container is-max-desktop">
      <div class=""columns is-centered">
          <div class="column is-full-width">
              <h2 class="title is-3">Experimental Results</h2>
              <br>
              <h3 class="subtitle is-4">Forget & Retain Assessments</h3>
              <div class="content has-text-justified">
                  <p>
                      In our evaluation of unlearning methods using the DUSK benchmark, we assess various metrics to determine the effectiveness of unlearning. 
                  </p>
              </div>
              <div class="content has-text-centered">
                  <div class="publication-image">
                      <img id="teaser" src="./static/images/resulttable.png" alt="Experimental Results Table"
                          style="width: 100%; max-width: 900px; height: auto; display: block; margin: 0 auto;">
                  </div>
              </div>
              <div class="content has-text-justified" style="border: 2px solid #ccc; padding: 15px; background-color: #f9f9f9; border-radius: 8px;">
                <ul style="margin: 0; padding-left: 20px;">
                  <li><strong>UFK (Unique Forget Knowledge):</strong>
                    Measures whether knowledge exclusive to the forget set is effectively removed.  
                  <br>
                  <li><strong>SK (Shared Knowledge):</strong>
                    Assesses if knowledge shared between the forget and retain sets is preserved.  
                  <br>
                  <li><strong>URK (Unique Retain Knowledge):</strong>
                    Verifies if knowledge exclusive to the retain set is maintained.  
                  <br>
                  <li><strong>DK (Downstream Knowledge):</strong>
                    Evaluates the modelâ€™s overall performance to ensure utility is preserved.
                </ul>
              </div>
          </div>
      </div>
    
      <!--<hr style="border: 1px solid #ccc; margin: 30px 0;">-->
      <br>
    
      <!-- Paper image. -->
      <div class="columns is-centered has-text-centered">
          <div class="column is-full-width">
              <div class="content has-text-centered">
                  <div class="publication-image">
                      <img id="teaser" src="./static/images/VerKnow.png" alt="Description of the image"
                          style="width: 100%; max-width: 900px; height: auto; display: block; margin: 0 auto;">
                  </div>
              </div>
          </div>
      </div>
      <!--/ Paper image. -->
      
      <!-- Summary of Figure 4 -->
      <div class="columns is-centered has-text-centered">
          <div class="column is-full-width">
              <div class="content has-text-justified">
                  <p>
                      Figure 4 presents a two-dimensional analysis of unlearning dynamics, focusing on the interaction between <strong>verbatim memorization</strong> and <strong>knowledge</strong> during the unlearning process.
                  </p>
              </div>
              <div class="content has-text-justified" style="border: 2px solid #ccc; padding: 15px; background-color: #f9f9f9; border-radius: 8px;">
                  <p>
                      <strong>1. Verbatim vs. Forget Knowledge (a):</strong> <br>
                      <em>Verbatim Memorization</em> is a key aspect of unlearning, assessing how well the model removes exact text from the forget set.
                  </p>
                  <p>
                      <strong>2. Forget Knowledge vs. Shared Knowledge (b):</strong> <br>
                      This part analyzes the relationship between <em>Forget Knowledge</em> (content to be removed) and <em>Shared Knowledge</em> (content shared between documents). Unlearning must remove unique knowledge from the forget set while preserving shared knowledge in the retain set.
                  </p>
               </div>
               <div class="content has-text-justified"> 
                  <p>
                      This figure visually illustrates the challenges of balancing the removal of verbatim content and maintaining important shared knowledge during unlearning.
                  </p>
              </div>
          </div>
      </div>
    
      <hr style="border: 1px solid #ccc; margin: 30px 0;">

      <h3 class="subtitle is-4">Distributional Assessments</h3>
      <!-- Paper image. -->
      <div class="columns is-centered has-text-centered">
          <div class="column is-full-width">
              <div class="content has-text-centered">
                  <div class="publication-image">
                      <img id="teaser" src="./static/images/mia.png" alt="Description of the image"
                          style="width: 100%; max-width: 900px; height: auto; display: block; margin: 0 auto;">
                  </div>
              </div>
          </div>
      </div>
      <!--/ Paper image. -->
      
      <!-- Summary of Figure 5 -->
      <div class="columns is-centered has-text-centered">
          <div class="column is-full-width">
              <div class="content has-text-justified">
                  <p>
                      Figure 5 illustrates <strong>Privacy Leakage</strong> and <strong>Retain Deviation</strong> throughout the unlearning process.
                  </p>
              </div>
              <div class="content has-text-justified" style="border: 2px solid #ccc; padding: 15px; background-color: #f9f9f9; border-radius: 8px;">
                  <p>
                      <strong>1. Privacy Leakage:</strong> Measures whether any residual information from the forget set remains in the model after unlearning, emphasizing the need to ensure that sensitive data is not inadvertently retained.
                  </p>
                  <p>
                      <strong>2. Retain Deviation:</strong> Evaluates how much the model's behavior deviates from its original performance on the retain set, ensuring that the unlearning process does not disrupt the modelâ€™s ability to perform on non-forgotten data.
                  </p>
              </div>
              <div class="content has-text-justified">
                  <p>
                      In multi-source settings, monitoring these metrics is crucial as they highlight a key challenge: selective forgetting becomes inherently difficult when the forget and retain sets share overlapping information. This overlap complicates the unlearning process, making it harder to remove only the targeted information while preserving the knowledge that should remain.
                  </p>
              </div>
          </div>
      </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{jeung2025safepath,
        title={SAFEPATH: Preventing Harmful Reasoning in Chain-of-Thought via Early Alignment},
        author={Jeung, Wonje and Yoon, Sangyeon and Kahng, Minsuk and No, Albert},
        journal={arXiv preprint arXiv:2505.14667},
        year={2025}
      }</code></pre>
  </div>
</section>

</body>
</html>