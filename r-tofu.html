<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="R-TOFU: Unlearning in Large Reasoning Models">
  <meta name="keywords" content="Benchmark, Large Reasoning Models, Large Language Models">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>R-TOFU: Unlearning in Large Reasoning Models</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/r-tofu/Icon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <style>
    body {
      background: linear-gradient(135deg, #f5f5f5 0%, #e8e8e8 100%);
      color: #222222;
      font-family: 'Helvetica Neue', Helvetica, Arial, sans-serif;
      line-height: 1.6;
    }
  
    .section.is-light {
      background-color: #ffffff;
      color: #222222;
      padding: 40px 20px;
      box-shadow: 0 2px 8px rgba(0, 0, 0, 0.05);
      border-radius: 8px;
    }
  
    .content p {
      color: #333333 !important;
      font-size: 16px;
    }
  
    .title, .subtitle {
      color: #111111 !important;
    }
  
    .publication-title {
      color: #8b2bb7;
      font-weight: 600;
      font-size: 24px;
    }
  
    .button.is-dark {
      background-color: #4a3f91;
      color: #ffffff;
      border-color: #4a3f91;
      transition: background-color 0.3s, border-color 0.3s;
    }
  
    .button.is-dark:hover {
      background-color: #372f6b;
      border-color: #372f6b;
    }
  
    a {
      color: #4a3f91;
      text-decoration: underline;
    }
  
    a:hover {
      color: #2f225a;
    }
  </style>  
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <img src="./static/images/r-tofu/Icon.png" alt="Logo" style="max-width: 180px; height: auto; margin-bottom: 30px;">
          <h1 class="title is-1 publication-title" style="color: #000000 !important;">R-TOFU: Unlearning in Large Reasoning Models</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href=".">Sangyeon Yoon</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://cryinginitial.github.io/">Wonje Jeung</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href=".">Albert No</a><sup>2â€ </sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Hongik University<sup>1</sup>,</span>
            <span class="author-block">Yonsei University<sup>2</sup></span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2505.15214"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2505.15214"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/AI-ISL/R-TOFU"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/collections/AI-ISL/r-tofu-unlearning-in-large-reasoning-models-6834177e1869c47bd0c787ce"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      ðŸ¤—
                  </span>
                  <span>Model & Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section is-light">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Large Reasoning Models (LRMs) embed private or copyrighted information not only in their final answers but also throughout multi-step chain-of-thought (CoT) traces, making reliable unlearning far more demanding than in standard LLMs. We introduce Reasoning-TOFU (R-TOFU), the first benchmark tailored to this setting. R-TOFU augments existing unlearning tasks with realistic CoT annotations and provides step-wise metrics that expose residual knowledge invisible to answer-level checks. Using R-TOFU, we carry out a comprehensive comparison of gradient-based and preference-optimization baselines and show that conventional answer-only objectives leave substantial forget traces in reasoning. We further propose Reasoned IDK, a preference-optimization variant that preserves coherent yet inconclusive reasoning, achieving a stronger balance between forgetting efficacy and model utility than earlier refusal styles. Finally, we identify a failure mode: decoding variants such as ZeroThink and LessThink can still reveal forgotten content despite seemingly successful unlearning, emphasizing the need to evaluate models under diverse decoding settings. Together, the benchmark, analysis, and new baseline establish a systematic foundation for studying and improving unlearning in LRMs while preserving their reasoning capabilities.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  <!-- Paper image. -->
  <div class="columns is-centered has-text-centered">
    <div class="column is-full-width">
      <div class="publication-image">
        <img id="teaser" src="./static/images/r-tofu/overview.png" alt="Teaser Image"
           style="width: 100%; max-width: 900px; height: auto; display: block; margin: 0 auto;">
      </div>
    </div>
  </div>
  <!--/ Paper image. -->
</section>
  
<section class="section is-light">
  <div class="container is-max-desktop">
      <div class="columns is-centered">
          <div class="column is-full-width">
              <h2 class="title is-3">Experimental Results</h2>
              <br>
              <h3 class="subtitle is-4">Overall Evaluation</h3>
              <div class="content has-text-centered">
                  <div class="publication-image">
                      <img id="teaser" src="./static/images/r-tofu/LRM_unlearning_Table2.png" alt="Experimental Results Table"
                          style="width: 100%; max-width: 900px; height: auto; display: block; margin: 0 auto;">
                  </div>
              </div>
              <div class="content has-text-justified" style="border: 2px solid #ccc; padding: 15px; background-color: #f9f9f9; border-radius: 8px;">
                <ul style="margin: 0; padding-left: 20px;">
                  <li><strong>Finding 1:</strong>
                    Unlearning only the final answer
                    is insufficient to remove forget information
                    embedded in the reasoning process.
                  <br>
                  <li><strong>Finding 2:</strong>
                    CoT-only unlearning provides
                    the best trade-off for gradient ascent-based
                    approaches in LRMs.
                  <br>
                  <li><strong>Finding 3:</strong>
                    Refusing through reasoning outperforms direct refusal in LRMs.
                </ul>
              </div>
          </div>
      </div>
    
      <!--<hr style="border: 1px solid #ccc; margin: 30px 0;">-->
      <br>
    

      
    
      <hr style="border: 1px solid #ccc; margin: 30px 0;">

      <h3 class="subtitle is-4">Decoding Strategies</h3>
      <!-- Paper image. -->
      <div class="columns is-centered has-text-centered">
          <div class="column is-full-width">
              <div class="content has-text-centered">
                  <div class="publication-image">
                      <img id="teaser" src="./static/images/r-tofu/rtofu_fig3.png" alt="Description of the image"
                          style="width: 100%; max-width: 900px; height: auto; display: block; margin: 0 auto;">
                  </div>
              </div>
          </div>
      </div>
      <!--/ Paper image. -->
      
      <!-- Summary of Figure 5 -->
      <div class="content has-text-justified" style="border: 2px solid #ccc; padding: 15px; background-color: #f9f9f9; border-radius: 8px;">
        <ul style="margin: 0; padding-left: 20px;">
          <li><strong>Finding 4:</strong>
            Decoding strategies like ZeroThink and LessThink may reveal residual
            knowledge even after effective unlearning.
        </ul>
      </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{yoon2025r,
      title={R-TOFU: Unlearning in Large Reasoning Models},
      author={Yoon, Sangyeon and Jeung, Wonje and No, Albert},
      journal={arXiv preprint arXiv:2505.15214},
      year={2025}
    }
</code></pre>
  </div>
</section>

</body>
</html>
